% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ModelLearner.R
\name{emRHLP}
\alias{emRHLP}
\title{emRHLP is used to fit a RHLP model.}
\usage{
emRHLP(X, Y, K, p, q = 1, variance_type = c("heteroskedastic",
  "homoskedastic"), n_tries = 1, max_iter = 1500, threshold = 1e-06,
  verbose = FALSE, verbose_IRLS = FALSE)
}
\arguments{
\item{X}{Numeric vector of length \emph{m} representing the covariates.}

\item{Y}{Matrix of size \eqn{(n, m)} representing \emph{n} functions of \code{X}
observed at points \eqn{1,\dots,m}.}

\item{K}{The number of regimes (mixture components).}

\item{p}{The order of the polynomial regression.}

\item{q}{Optional. The dimension of the logistic regression. For the purpose of
segmentation, it must be set to 1.}

\item{variance_type}{Optional character indicating if the model is
"homoskedastic" or "heteroskedastic". By default the model is
"heteroskedastic".}

\item{n_tries}{Optional. Number of times EM algorithm will be launched.
The solution providing the highest log-likelihood will be returned.

If \code{n_tries} > 1, then for the first pass, parameters are initialized
by uniformly segmenting the data into K segments, and for the next passes,
parameters are initialized by randomly segmenting the data into K contiguous
segments.}

\item{max_iter}{Optional. The maximum number of iterations for the EM algorithm.}

\item{threshold}{Optional. A numeric value specifying the threshold for the relative
difference of log-likelihood between two steps  of the EM as stopping
criteria.}

\item{verbose}{Optional. A logical value indicating whether values of the
log-likelihood should be printed during EM iterations.}

\item{verbose_IRLS}{Optional. A logical value indicating whether values of the
criterion optimized by IRLS should be printed at each step of the EM
algorithm.}
}
\value{
EM returns an object of class \link{ModelRHLP}.
}
\description{
emRHLP is used to fit a RHLP model. The estimation method is performed by
the Expectation-Maximization algorithm.
}
\details{
emRHLP function is based on the EM algorithm. This function starts
with an initialization of the parameters done by the method \code{initParam} of
the class \link{ParamRHLP}, then it alternates between a E-Step
(method of the class \link{StatRHLP}) and a M-Step (method of the class
\link{ParamRHLP}) until convergence (until the absolute difference of
log-likelihood between two steps of the EM algorithm is less than the
\code{threshold} parameter).
}
\seealso{
\link{ModelRHLP}, \link{ParamRHLP}, \link{StatRHLP}
}
